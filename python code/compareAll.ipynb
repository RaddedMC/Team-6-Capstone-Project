{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8541ce-7999-4125-af70-62cd40a733c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## comapre all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdb74b-73d1-46fa-abba-95cb101808b9",
   "metadata": {},
   "source": [
    "## nothing haappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ca69e-f19f-4d6a-9506-95c6300d6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.09940934181213379\n",
      "the process time is 0.07921051979064941\n",
      "the process time is 0.28438758850097656\n",
      "the process time is 0.5646357536315918\n",
      "the process time is 0.2830629348754883\n",
      "the process time is 0.2856466770172119\n",
      "the process time is 0.28026366233825684\n",
      "the process time is 0.2788686752319336\n",
      "the process time is 0.08571958541870117\n",
      "the process time is 0.28918027877807617\n",
      "the process time is 0.2836780548095703\n",
      "the process time is 0.2809774875640869\n",
      "the process time is 0.2839949131011963\n",
      "the process time is 0.28249049186706543\n",
      "the process time is 0.0841975212097168\n",
      "the process time is 0.28843164443969727\n",
      "the process time is 0.08372187614440918\n",
      "the process time is 0.0887296199798584\n",
      "the process time is 0.2879514694213867\n",
      "the process time is 0.2878150939941406\n",
      "the process time is 0.28119897842407227\n",
      "the process time is 0.2814309597015381\n",
      "the process time is 0.2824571132659912\n",
      "the process time is 0.2883918285369873\n",
      "the process time is 0.28358936309814453\n",
      "the process time is 0.28495311737060547\n",
      "the process time is 0.28543996810913086\n",
      "the process time is 0.07608485221862793\n",
      "the process time is 0.08235955238342285\n",
      "the process time is 0.08122515678405762\n",
      "the process time is 0.28526806831359863\n",
      "the process time is 0.28356122970581055\n",
      "the process time is 0.0819857120513916\n",
      "the process time is 0.2938988208770752\n",
      "the process time is 0.27954840660095215\n",
      "the process time is 0.2819352149963379\n",
      "the process time is 0.2806210517883301\n",
      "the process time is 0.281360387802124\n",
      "the process time is 0.2822597026824951\n",
      "the process time is 0.0747079849243164\n",
      "the process time is 0.2821509838104248\n",
      "the process time is 0.2862224578857422\n",
      "the process time is 0.283109188079834\n",
      "the process time is 0.2832145690917969\n",
      "the process time is 0.2850615978240967\n",
      "the process time is 0.2848937511444092\n",
      "the process time is 0.28395867347717285\n",
      "the process time is 0.28594517707824707\n",
      "the process time is 0.28487563133239746\n",
      "the process time is 0.2826042175292969\n",
      "the process time is 0.29016590118408203\n",
      "the process time is 0.29079103469848633\n",
      "the process time is 0.28354477882385254\n",
      "the process time is 0.27799010276794434\n",
      "the process time is 0.28519415855407715\n",
      "the process time is 0.28713178634643555\n",
      "the process time is 0.27843475341796875\n",
      "the process time is 0.2837221622467041\n",
      "the process time is 0.28788328170776367\n",
      "the process time is 0.2836179733276367\n",
      "the process time is 0.2869100570678711\n",
      "the process time is 0.28235650062561035\n",
      "the process time is 0.08040022850036621\n",
      "the process time is 0.29108285903930664\n",
      "the process time is 0.278364896774292\n",
      "the process time is 0.28548359870910645\n",
      "the process time is 0.2828640937805176\n",
      "the process time is 0.08444738388061523\n",
      "the process time is 0.2861621379852295\n",
      "the process time is 0.2857959270477295\n",
      "the process time is 0.07715940475463867\n",
      "the process time is 0.08121776580810547\n",
      "the process time is 0.28569650650024414\n",
      "the process time is 0.08649277687072754\n",
      "the process time is 0.28507184982299805\n",
      "the process time is 0.2869880199432373\n",
      "the process time is 0.2833669185638428\n",
      "the process time is 0.28304529190063477\n",
      "the process time is 0.28708338737487793\n",
      "the process time is 0.2838287353515625\n",
      "the process time is 0.2775540351867676\n",
      "the process time is 0.28540682792663574\n",
      "the process time is 0.09084033966064453\n",
      "the process time is 0.08992481231689453\n",
      "the process time is 0.07717728614807129\n",
      "the process time is 0.08206486701965332\n",
      "the process time is 0.08065605163574219\n",
      "the process time is 0.08321523666381836\n",
      "the process time is 0.3694734573364258\n",
      "the process time is 0.07663989067077637\n",
      "the process time is 0.356853723526001\n",
      "the process time is 0.08377671241760254\n",
      "the process time is 0.36345791816711426\n",
      "the process time is 0.2868337631225586\n",
      "the process time is 0.0779714584350586\n",
      "the process time is 0.08250999450683594\n",
      "the process time is 0.08208394050598145\n",
      "the process time is 0.08143472671508789\n",
      "the process time is 0.0789637565612793\n",
      "the process time is 0.08123040199279785\n",
      "the process time is 0.08412551879882812\n",
      "the process time is 0.08934831619262695\n",
      "the process time is 0.08118820190429688\n",
      "the process time is 0.0799400806427002\n",
      "the process time is 0.08850765228271484\n",
      "the process time is 0.08823633193969727\n",
      "the process time is 0.2823915481567383\n",
      "the process time is 0.5597255229949951\n",
      "the process time is 0.09633398056030273\n",
      "the process time is 0.07483887672424316\n",
      "the process time is 0.09324240684509277\n",
      "the process time is 0.08920812606811523\n",
      "the process time is 0.08465433120727539\n",
      "the process time is 0.08203601837158203\n",
      "the process time is 0.0811929702758789\n",
      "the process time is 0.08798432350158691\n",
      "the process time is 0.08468890190124512\n",
      "the process time is 0.27311086654663086\n",
      "the process time is 0.28044915199279785\n",
      "the process time is 0.08901548385620117\n",
      "the process time is 0.28940486907958984\n",
      "the process time is 0.08201122283935547\n",
      "the process time is 0.2844557762145996\n",
      "the process time is 0.28876399993896484\n",
      "the process time is 0.28148555755615234\n",
      "the process time is 0.2825028896331787\n",
      "the process time is 0.5641303062438965\n",
      "the process time is 0.2806065082550049\n",
      "the process time is 0.5803301334381104\n",
      "the process time is 0.2771110534667969\n",
      "the process time is 0.28986477851867676\n",
      "the process time is 0.28256964683532715\n",
      "the process time is 0.2814469337463379\n",
      "the process time is 0.2981572151184082\n",
      "the process time is 0.2830991744995117\n",
      "the process time is 0.08171844482421875\n",
      "the process time is 0.30088067054748535\n",
      "the process time is 0.2830851078033447\n",
      "the process time is 0.2832009792327881\n",
      "the process time is 0.2811853885650635\n",
      "the process time is 0.28400516510009766\n",
      "the process time is 0.08089733123779297\n",
      "the process time is 0.2825357913970947\n",
      "the process time is 0.27881765365600586\n",
      "the process time is 0.28328752517700195\n",
      "the process time is 0.08039355278015137\n",
      "the process time is 0.27893733978271484\n",
      "the process time is 0.2780792713165283\n",
      "the process time is 0.2869443893432617\n",
      "the process time is 0.2841160297393799\n",
      "the process time is 0.28495359420776367\n",
      "the process time is 0.28885769844055176\n",
      "the process time is 0.28562498092651367\n",
      "the process time is 0.27980756759643555\n",
      "the process time is 0.08075189590454102\n",
      "the process time is 0.28418588638305664\n",
      "the process time is 0.2825808525085449\n",
      "the process time is 0.28760337829589844\n",
      "the process time is 0.28295207023620605\n",
      "the process time is 0.2849147319793701\n",
      "the process time is 0.5650687217712402\n",
      "the process time is 0.27918028831481934\n",
      "the process time is 0.08066368103027344\n",
      "the process time is 0.07831144332885742\n",
      "the process time is 0.2816331386566162\n",
      "the process time is 0.07759690284729004\n",
      "the process time is 0.07816505432128906\n",
      "the process time is 0.27996253967285156\n",
      "the process time is 0.28862571716308594\n",
      "the process time is 0.28206467628479004\n",
      "the process time is 0.2784097194671631\n",
      "the process time is 0.2792956829071045\n",
      "the process time is 0.357621431350708\n",
      "the process time is 0.28532910346984863\n",
      "the process time is 0.2896387577056885\n",
      "the process time is 0.3731536865234375\n",
      "the process time is 0.2817683219909668\n",
      "the process time is 0.28456544876098633\n",
      "the process time is 0.3668644428253174\n",
      "the process time is 0.08925104141235352\n",
      "the process time is 0.08621549606323242\n",
      "the process time is 0.08511662483215332\n",
      "the process time is 0.0834040641784668\n",
      "the process time is 0.2878117561340332\n",
      "the process time is 0.08648228645324707\n",
      "the process time is 0.08291769027709961\n",
      "the process time is 0.1092674732208252\n",
      "the process time is 0.08420658111572266\n",
      "the process time is 0.08382630348205566\n",
      "the process time is 0.07765817642211914\n",
      "the process time is 0.08284807205200195\n",
      "the process time is 0.08085131645202637\n",
      "the process time is 0.07518196105957031\n",
      "the process time is 0.2852663993835449\n",
      "the process time is 0.5620517730712891\n",
      "the process time is 0.2780008316040039\n",
      "the process time is 0.28516602516174316\n",
      "the process time is 0.28290343284606934\n",
      "the process time is 0.2823472023010254\n",
      "the process time is 0.08135986328125\n",
      "the process time is 0.2864222526550293\n",
      "the process time is 0.0862421989440918\n",
      "the process time is 0.2807602882385254\n",
      "the process time is 0.08998751640319824\n",
      "the process time is 0.28775978088378906\n",
      "the process time is 0.07780790328979492\n",
      "the process time is 0.08524084091186523\n",
      "the process time is 0.2972221374511719\n",
      "the process time is 0.07758378982543945\n",
      "the process time is 0.08984756469726562\n",
      "the process time is 0.08901143074035645\n",
      "the process time is 0.29941487312316895\n",
      "the process time is 0.07982444763183594\n",
      "the process time is 0.2872195243835449\n",
      "the process time is 0.28499722480773926\n",
      "the process time is 0.27714037895202637\n",
      "the process time is 0.2840995788574219\n",
      "the process time is 0.2782621383666992\n",
      "the process time is 0.2816455364227295\n",
      "the process time is 0.277815580368042\n",
      "the process time is 0.28322529792785645\n",
      "the process time is 0.2879340648651123\n",
      "the process time is 0.2810935974121094\n",
      "the process time is 0.2815401554107666\n",
      "the process time is 0.2847285270690918\n",
      "the process time is 0.2818715572357178\n",
      "the process time is 0.274688720703125\n",
      "the process time is 0.2821812629699707\n",
      "the process time is 0.2818636894226074\n",
      "the process time is 0.27870655059814453\n",
      "the process time is 0.2771463394165039\n",
      "the process time is 0.08222603797912598\n",
      "the process time is 0.28045058250427246\n",
      "the process time is 0.2830047607421875\n",
      "the process time is 0.28720664978027344\n",
      "the process time is 0.2798435688018799\n",
      "the process time is 0.2841072082519531\n",
      "the process time is 0.2842898368835449\n",
      "the process time is 0.28355956077575684\n",
      "the process time is 0.2770698070526123\n",
      "the process time is 0.08265519142150879\n",
      "the process time is 0.08584737777709961\n",
      "the process time is 0.08501529693603516\n",
      "the process time is 0.08368873596191406\n",
      "the process time is 0.08706021308898926\n",
      "the process time is 0.08472943305969238\n",
      "the process time is 0.2904069423675537\n",
      "the process time is 0.37068986892700195\n",
      "the process time is 0.28450655937194824\n",
      "the process time is 0.3694465160369873\n",
      "the process time is 0.28647351264953613\n",
      "the process time is 0.28128671646118164\n",
      "the process time is 0.29311466217041016\n",
      "the process time is 0.2869241237640381\n",
      "the process time is 0.27542638778686523\n",
      "the process time is 0.2775869369506836\n",
      "the process time is 0.31499147415161133\n",
      "the process time is 0.2836649417877197\n",
      "the process time is 0.0857994556427002\n",
      "the process time is 0.28513002395629883\n",
      "the process time is 0.07850265502929688\n",
      "the process time is 0.2905559539794922\n",
      "the process time is 0.2850651741027832\n",
      "the process time is 0.5647153854370117\n",
      "the process time is 0.28067970275878906\n",
      "the process time is 0.28478193283081055\n",
      "the process time is 0.2784914970397949\n",
      "the process time is 0.27634406089782715\n",
      "the process time is 0.2805910110473633\n",
      "the process time is 0.2797689437866211\n",
      "the process time is 0.28236865997314453\n",
      "the process time is 0.2799057960510254\n",
      "the process time is 0.27901291847229004\n",
      "the process time is 0.28177809715270996\n",
      "the process time is 0.2830986976623535\n",
      "the process time is 0.08334970474243164\n",
      "the process time is 0.08183503150939941\n",
      "the process time is 0.2830166816711426\n",
      "the process time is 0.2763240337371826\n",
      "the process time is 0.27393198013305664\n",
      "the process time is 0.08060312271118164\n",
      "the process time is 0.0857081413269043\n",
      "the process time is 0.08571648597717285\n",
      "the process time is 0.08117103576660156\n",
      "the process time is 0.08487677574157715\n",
      "the process time is 0.2868363857269287\n",
      "the process time is 0.2807929515838623\n",
      "the process time is 0.2832300662994385\n",
      "the process time is 0.5645008087158203\n",
      "the process time is 0.28424906730651855\n",
      "the process time is 0.5708901882171631\n",
      "the process time is 0.08053064346313477\n",
      "the process time is 0.15767884254455566\n",
      "the process time is 0.28442955017089844\n",
      "the process time is 0.5705397129058838\n",
      "the process time is 0.28324031829833984\n",
      "the process time is 0.2879934310913086\n",
      "the process time is 0.2977578639984131\n",
      "the process time is 0.28383898735046387\n",
      "the process time is 0.28516340255737305\n",
      "the process time is 0.28077030181884766\n",
      "the process time is 0.28685927391052246\n",
      "the process time is 0.2805337905883789\n",
      "the process time is 0.27957963943481445\n",
      "the process time is 0.08474326133728027\n",
      "the process time is 0.07819676399230957\n",
      "the process time is 0.281665563583374\n",
      "the process time is 0.08122992515563965\n",
      "the process time is 0.08521151542663574\n",
      "the process time is 0.07932710647583008\n",
      "the process time is 0.08883833885192871\n",
      "the process time is 0.08021831512451172\n",
      "the process time is 0.2840397357940674\n",
      "the process time is 0.28064393997192383\n",
      "the process time is 0.28461790084838867\n",
      "the process time is 0.2820863723754883\n",
      "the process time is 0.27866530418395996\n",
      "the process time is 0.2934229373931885\n",
      "the process time is 0.2810204029083252\n",
      "the process time is 0.28379058837890625\n",
      "the process time is 0.2861454486846924\n",
      "the process time is 0.28464293479919434\n",
      "the process time is 0.0832376480102539\n",
      "the process time is 0.2862730026245117\n",
      "the process time is 0.2759385108947754\n",
      "the process time is 0.2838099002838135\n",
      "the process time is 0.2856118679046631\n",
      "the process time is 0.2825155258178711\n",
      "the process time is 0.2831902503967285\n",
      "the process time is 0.29152607917785645\n",
      "the process time is 0.27982211112976074\n",
      "the process time is 0.28249168395996094\n",
      "the process time is 0.08366632461547852\n",
      "the process time is 0.28670692443847656\n",
      "the process time is 0.2840118408203125\n",
      "the process time is 0.2781813144683838\n",
      "the process time is 0.2763857841491699\n",
      "the process time is 0.2843587398529053\n",
      "the process time is 0.2799875736236572\n",
      "the process time is 0.28754544258117676\n",
      "the process time is 0.28052330017089844\n",
      "the process time is 0.28379106521606445\n",
      "the process time is 0.2875213623046875\n",
      "the process time is 0.2786695957183838\n",
      "the process time is 0.2791590690612793\n",
      "the process time is 0.31063127517700195\n",
      "the process time is 0.28194236755371094\n",
      "the process time is 0.08071184158325195\n",
      "the process time is 0.2854781150817871\n",
      "the process time is 0.2790515422821045\n",
      "the process time is 0.08306050300598145\n",
      "the process time is 0.08693647384643555\n",
      "the process time is 0.08318901062011719\n",
      "the process time is 0.08324074745178223\n",
      "the process time is 0.0833122730255127\n",
      "the process time is 0.28984785079956055\n",
      "the process time is 0.282520055770874\n",
      "the process time is 0.28593921661376953\n",
      "the process time is 0.2885575294494629\n",
      "the process time is 0.2821645736694336\n",
      "the process time is 0.2772033214569092\n",
      "the process time is 0.2727348804473877\n",
      "the process time is 0.2853868007659912\n",
      "the process time is 0.29331111907958984\n",
      "the process time is 0.0787038803100586\n",
      "the process time is 0.0769810676574707\n",
      "the process time is 0.08221602439880371\n",
      "the process time is 0.08538246154785156\n",
      "the process time is 0.2832458019256592\n",
      "the process time is 0.08533954620361328\n",
      "the process time is 0.08220696449279785\n",
      "the process time is 0.0771486759185791\n",
      "the process time is 0.08526229858398438\n",
      "the process time is 0.09200143814086914\n",
      "the process time is 0.08571648597717285\n",
      "the process time is 0.28447389602661133\n",
      "the process time is 0.28101301193237305\n",
      "the process time is 0.2817847728729248\n",
      "the process time is 0.2866697311401367\n",
      "the process time is 0.27620577812194824\n",
      "the process time is 0.2788231372833252\n",
      "the process time is 0.2807807922363281\n",
      "the process time is 0.2822258472442627\n",
      "the process time is 0.28235602378845215\n",
      "the process time is 0.2856302261352539\n",
      "the process time is 0.3039712905883789\n",
      "the process time is 0.3008122444152832\n",
      "the process time is 0.28159117698669434\n",
      "the process time is 0.28533005714416504\n",
      "the process time is 0.28465938568115234\n",
      "the process time is 0.08196139335632324\n",
      "the process time is 0.08282065391540527\n",
      "the process time is 0.2907683849334717\n",
      "the process time is 0.2814936637878418\n",
      "the process time is 0.2820117473602295\n",
      "the process time is 0.2804718017578125\n",
      "the process time is 0.2796595096588135\n",
      "the process time is 0.28625917434692383\n",
      "the process time is 0.2860252857208252\n",
      "the process time is 0.2829105854034424\n",
      "the process time is 0.2815263271331787\n",
      "the process time is 0.28189706802368164\n",
      "the process time is 0.28578639030456543\n",
      "the process time is 0.27960753440856934\n",
      "the process time is 0.2813255786895752\n",
      "the process time is 0.28421998023986816\n",
      "the process time is 0.2781393527984619\n",
      "the process time is 0.2818896770477295\n",
      "the process time is 0.2780601978302002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "# MediaPipe Hands initialization\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "# GPU availability check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Gesture recognition model path and class names\n",
    "model_path = \"./efficientnet1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"efficientnet_b3a\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to get PyTorch transforms\n",
    "def get_torch_transforms(img_size=224):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomRotation((-5, 5)),\n",
    "            transforms.RandomAutocontrast(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'V' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "\n",
    "    if hand_landmarks:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for index, handLMs in enumerate(hand_landmarks):\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "\n",
    "            x_min = max(0, x_min - 50)\n",
    "            y_min = max(0, y_min - 50)\n",
    "            x_max = min(w, x_max + 50)\n",
    "            y_max = min(h, y_max + 50)\n",
    "\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "           \n",
    "            \n",
    "            cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "            input_tensor = transform(cropped_frame).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                probabilities = F.softmax(output[0], dim=0)\n",
    "                predicted_class = torch.argmax(probabilities).item()\n",
    "                #use getsure control it\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                #end of it\n",
    "                predict_name = classes_names[predicted_class] + \" for Hand \" + str(index + 1)\n",
    "\n",
    "\n",
    "            cv2.putText(frame, predict_name, (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "            # Get timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate processing time\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        #\"esc\" to quit\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "eww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1b836-f562-4f81-81ff-2207f312927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2559b95-50e5-452e-a633-8a838bd7cf1d",
   "metadata": {},
   "source": [
    "## downsampleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0affc708-c029-4043-b560-1640ec9b9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pytorchMethod\\pytorchClassification2\\pytorchEnv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.053270816802978516\n",
      "the process time is 0.030899763107299805\n",
      "the process time is 0.030931711196899414\n",
      "the process time is 0.031241655349731445\n",
      "the process time is 0.030613183975219727\n",
      "the process time is 0.031070947647094727\n",
      "the process time is 0.030059337615966797\n",
      "the process time is 0.03051018714904785\n",
      "the process time is 0.03112196922302246\n",
      "the process time is 0.0307772159576416\n",
      "the process time is 0.03036665916442871\n",
      "the process time is 0.03151965141296387\n",
      "the process time is 0.03053116798400879\n",
      "the process time is 0.03140568733215332\n",
      "the process time is 0.03161478042602539\n",
      "the process time is 0.031122684478759766\n",
      "the process time is 0.0308685302734375\n",
      "the process time is 0.03142356872558594\n",
      "the process time is 0.030759572982788086\n",
      "the process time is 0.030615806579589844\n",
      "the process time is 0.03162956237792969\n",
      "the process time is 0.030982017517089844\n",
      "the process time is 0.0314030647277832\n",
      "the process time is 0.02999091148376465\n",
      "the process time is 0.030720949172973633\n",
      "the process time is 0.03040003776550293\n",
      "the process time is 0.03056812286376953\n",
      "the process time is 0.031174659729003906\n",
      "the process time is 0.027454137802124023\n",
      "the process time is 0.0317683219909668\n",
      "the process time is 0.031087636947631836\n",
      "the process time is 0.03166508674621582\n",
      "the process time is 0.030954837799072266\n",
      "the process time is 0.0375971794128418\n",
      "the process time is 0.030117511749267578\n",
      "the process time is 0.02954411506652832\n",
      "the process time is 0.030864238739013672\n",
      "the process time is 0.031096458435058594\n",
      "the process time is 0.030556678771972656\n",
      "the process time is 0.03051471710205078\n",
      "the process time is 0.03018808364868164\n",
      "the process time is 0.02999114990234375\n",
      "the process time is 0.031100034713745117\n",
      "the process time is 0.030616283416748047\n",
      "the process time is 0.03014540672302246\n",
      "the process time is 0.03141474723815918\n",
      "the process time is 0.031087398529052734\n",
      "the process time is 0.03110647201538086\n",
      "the process time is 0.03069901466369629\n",
      "the process time is 0.031449317932128906\n",
      "the process time is 0.03083491325378418\n",
      "the process time is 0.039186716079711914\n",
      "the process time is 0.34470057487487793\n",
      "the process time is 0.3390820026397705\n",
      "the process time is 0.33965325355529785\n",
      "the process time is 0.21706295013427734\n",
      "the process time is 0.3105926513671875\n",
      "the process time is 0.3525269031524658\n",
      "the process time is 0.13692474365234375\n",
      "the process time is 0.13705801963806152\n",
      "the process time is 0.13686633110046387\n",
      "the process time is 0.13276362419128418\n",
      "the process time is 0.3264749050140381\n",
      "the process time is 0.040605783462524414\n",
      "the process time is 0.02883148193359375\n",
      "the process time is 0.03178763389587402\n",
      "the process time is 0.02938556671142578\n",
      "the process time is 0.32349300384521484\n",
      "the process time is 0.2267763614654541\n",
      "the process time is 0.10654616355895996\n",
      "the process time is 0.3287465572357178\n",
      "the process time is 0.1368110179901123\n",
      "the process time is 0.15339279174804688\n",
      "the process time is 0.24703621864318848\n",
      "the process time is 0.03053569793701172\n",
      "the process time is 0.3339416980743408\n",
      "the process time is 0.15150737762451172\n",
      "the process time is 0.3388662338256836\n",
      "the process time is 0.6169874668121338\n",
      "the process time is 0.02888631820678711\n",
      "the process time is 0.3333323001861572\n",
      "the process time is 0.04352068901062012\n",
      "the process time is 0.11320137977600098\n",
      "the process time is 0.33803248405456543\n",
      "the process time is 0.13775992393493652\n",
      "the process time is 0.12722516059875488\n",
      "the process time is 0.23093581199645996\n",
      "the process time is 0.10625529289245605\n",
      "the process time is 0.23505759239196777\n",
      "the process time is 0.035813331604003906\n",
      "the process time is 0.14864802360534668\n",
      "the process time is 0.1543107032775879\n",
      "the process time is 0.24161148071289062\n",
      "the process time is 0.030055522918701172\n",
      "the process time is 0.1399550437927246\n",
      "the process time is 0.22206878662109375\n",
      "the process time is 0.031067848205566406\n",
      "the process time is 0.13981389999389648\n",
      "the process time is 0.13927149772644043\n",
      "the process time is 0.33877134323120117\n",
      "the process time is 0.04413747787475586\n",
      "the process time is 0.03009653091430664\n",
      "the process time is 0.03196430206298828\n",
      "the process time is 0.031038522720336914\n",
      "the process time is 0.029547929763793945\n",
      "the process time is 0.026552677154541016\n",
      "the process time is 0.33657383918762207\n",
      "the process time is 0.6131837368011475\n",
      "the process time is 0.29845714569091797\n",
      "the process time is 0.32311391830444336\n",
      "the process time is 0.32588839530944824\n",
      "the process time is 0.33537960052490234\n",
      "the process time is 0.04332304000854492\n",
      "the process time is 0.3344407081604004\n",
      "the process time is 0.34279632568359375\n",
      "the process time is 0.04483461380004883\n",
      "the process time is 0.3397982120513916\n",
      "the process time is 0.04376077651977539\n",
      "the process time is 0.1361842155456543\n",
      "the process time is 0.12455296516418457\n",
      "the process time is 0.05010867118835449\n",
      "the process time is 0.031098604202270508\n",
      "the process time is 0.3302040100097656\n",
      "the process time is 0.04366278648376465\n",
      "the process time is 0.12140226364135742\n",
      "the process time is 0.3383805751800537\n",
      "the process time is 0.34073901176452637\n",
      "the process time is 0.04724383354187012\n",
      "the process time is 0.04512977600097656\n",
      "the process time is 0.13900232315063477\n",
      "the process time is 0.06461000442504883\n",
      "the process time is 0.030923843383789062\n",
      "the process time is 0.33570122718811035\n",
      "the process time is 0.04609322547912598\n",
      "the process time is 0.11932110786437988\n",
      "the process time is 0.05513954162597656\n",
      "the process time is 0.03550124168395996\n",
      "the process time is 0.12099027633666992\n",
      "the process time is 0.1380634307861328\n",
      "the process time is 0.06126046180725098\n",
      "the process time is 0.3425266742706299\n",
      "the process time is 0.14045023918151855\n",
      "the process time is 0.3266122341156006\n",
      "the process time is 0.6323566436767578\n",
      "the process time is 0.3113410472869873\n",
      "the process time is 0.32404398918151855\n",
      "the process time is 0.32103848457336426\n",
      "the process time is 0.327376127243042\n",
      "the process time is 0.3183557987213135\n",
      "the process time is 0.32497668266296387\n",
      "the process time is 0.3358292579650879\n",
      "the process time is 0.32700061798095703\n",
      "the process time is 0.0442051887512207\n",
      "the process time is 0.026485681533813477\n",
      "the process time is 0.029706716537475586\n",
      "the process time is 0.03432631492614746\n",
      "the process time is 0.029535293579101562\n",
      "the process time is 0.029284954071044922\n",
      "the process time is 0.02718210220336914\n",
      "the process time is 0.044866323471069336\n",
      "the process time is 0.03258395195007324\n",
      "the process time is 0.031047582626342773\n",
      "the process time is 0.030302762985229492\n",
      "the process time is 0.02716851234436035\n",
      "the process time is 0.031211137771606445\n",
      "the process time is 0.030882596969604492\n",
      "the process time is 0.027568578720092773\n",
      "the process time is 0.027037858963012695\n",
      "the process time is 0.02512526512145996\n",
      "the process time is 0.03020954132080078\n",
      "the process time is 0.030582904815673828\n",
      "the process time is 0.02841043472290039\n",
      "the process time is 0.03136181831359863\n",
      "the process time is 0.032778024673461914\n",
      "the process time is 0.028386831283569336\n",
      "the process time is 0.029901981353759766\n",
      "the process time is 0.03338479995727539\n",
      "the process time is 0.029088973999023438\n",
      "the process time is 0.026394128799438477\n",
      "the process time is 0.030412673950195312\n",
      "the process time is 0.027562856674194336\n",
      "the process time is 0.03082108497619629\n",
      "the process time is 0.029572725296020508\n",
      "the process time is 0.04291272163391113\n",
      "the process time is 0.03124094009399414\n",
      "the process time is 0.04390740394592285\n",
      "the process time is 0.028698444366455078\n",
      "the process time is 0.027085304260253906\n",
      "the process time is 0.029536008834838867\n",
      "the process time is 0.04223752021789551\n",
      "the process time is 0.029226064682006836\n",
      "the process time is 0.04050326347351074\n",
      "the process time is 0.029112577438354492\n",
      "the process time is 0.03132224082946777\n",
      "the process time is 0.030123233795166016\n",
      "the process time is 0.030545473098754883\n",
      "the process time is 0.026194095611572266\n",
      "the process time is 0.030512332916259766\n",
      "the process time is 0.029382705688476562\n",
      "the process time is 0.03257036209106445\n",
      "the process time is 0.029003381729125977\n",
      "the process time is 0.028847694396972656\n",
      "the process time is 0.03112936019897461\n",
      "the process time is 0.0440669059753418\n",
      "the process time is 0.030184507369995117\n",
      "the process time is 0.029555082321166992\n",
      "the process time is 0.04082012176513672\n",
      "the process time is 0.028124570846557617\n",
      "the process time is 0.030869722366333008\n",
      "the process time is 0.022362232208251953\n",
      "the process time is 0.022078514099121094\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "model_path = \"./efficientnet1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"efficientnet_b3a\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "    \n",
    "        #do nothing\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Downsample factor (skip every N frames)\n",
    "downsample_factor = 2\n",
    "downsample_counter = 0\n",
    "classA=\"nothing\"\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "    # Downsample frames\n",
    "    if downsample_counter % downsample_factor == 0:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                classA= classes_names[predicted_class]\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        \n",
    "        # Get timestamp after processing and before showing the frame\n",
    "        end_time = time.time()\n",
    "        # Calculate processing time\n",
    "        processing_time = end_time - start_time\n",
    "        print(\"the process time is \"+ str(processing_time))\n",
    "            \n",
    "    else:\n",
    "            gesture_control(classA)\n",
    "\n",
    "    downsample_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475231a-3149-4dba-85e0-78cc0e6aebeb",
   "metadata": {},
   "source": [
    "## multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a40a0-396d-4a41-83c0-5d0929942d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.18364930152893066\n",
      "the process time is 0.06861138343811035\n",
      "the process time is 0.2850613594055176\n",
      "the process time is 0.2715585231781006\n",
      "the process time is 0.27010512351989746\n",
      "the process time is 0.558957576751709\n",
      "the process time is 0.276611328125\n",
      "the process time is 0.2722659111022949\n",
      "the process time is 0.27386903762817383\n",
      "the process time is 0.27530360221862793\n",
      "the process time is 0.28975367546081543\n",
      "the process time is 0.27323174476623535\n",
      "the process time is 0.2790255546569824\n",
      "the process time is 0.2866668701171875\n",
      "the process time is 0.2762579917907715\n",
      "the process time is 0.28015899658203125\n",
      "the process time is 0.2691612243652344\n",
      "the process time is 0.2730860710144043\n",
      "the process time is 0.2801487445831299\n",
      "the process time is 0.2746121883392334\n",
      "the process time is 0.2786219120025635\n",
      "the process time is 0.07120609283447266\n",
      "the process time is 0.27913546562194824\n",
      "the process time is 0.27172207832336426\n",
      "the process time is 0.2702298164367676\n",
      "the process time is 0.5438246726989746\n",
      "the process time is 0.288787841796875\n",
      "the process time is 0.26959228515625\n",
      "the process time is 0.27526426315307617\n",
      "the process time is 0.27988290786743164\n",
      "the process time is 0.2796764373779297\n",
      "the process time is 0.26970362663269043\n",
      "the process time is 0.29144835472106934\n",
      "the process time is 0.27565670013427734\n",
      "the process time is 0.27701306343078613\n",
      "the process time is 0.29682469367980957\n",
      "the process time is 0.27345943450927734\n",
      "the process time is 0.27268528938293457\n",
      "the process time is 0.27192234992980957\n",
      "the process time is 0.27770066261291504\n",
      "the process time is 0.2853264808654785\n",
      "the process time is 0.2708854675292969\n",
      "the process time is 0.5487251281738281\n",
      "the process time is 0.2748861312866211\n",
      "the process time is 0.5466063022613525\n",
      "the process time is 0.2677433490753174\n",
      "the process time is 0.30346059799194336\n",
      "the process time is 0.27040815353393555\n",
      "the process time is 0.27756333351135254\n",
      "the process time is 0.2812654972076416\n",
      "the process time is 0.2779397964477539\n",
      "the process time is 0.2707328796386719\n",
      "the process time is 0.2720348834991455\n",
      "the process time is 0.2714202404022217\n",
      "the process time is 0.2742784023284912\n",
      "the process time is 0.28167080879211426\n",
      "the process time is 0.2757446765899658\n",
      "the process time is 0.27808547019958496\n",
      "the process time is 0.27693605422973633\n",
      "the process time is 0.2726147174835205\n",
      "the process time is 0.2728743553161621\n",
      "the process time is 0.28227686882019043\n",
      "the process time is 0.10418343544006348\n",
      "the process time is 0.2812032699584961\n",
      "the process time is 0.27675461769104004\n",
      "the process time is 0.0754702091217041\n",
      "the process time is 0.569744348526001\n",
      "the process time is 0.27440881729125977\n",
      "the process time is 0.27689504623413086\n",
      "the process time is 0.2686429023742676\n",
      "the process time is 0.27904200553894043\n",
      "the process time is 0.2816641330718994\n",
      "the process time is 0.269622802734375\n",
      "the process time is 0.2787325382232666\n",
      "the process time is 0.27637267112731934\n",
      "the process time is 0.27825140953063965\n",
      "the process time is 0.2779216766357422\n",
      "the process time is 0.2759239673614502\n",
      "the process time is 0.3019859790802002\n",
      "the process time is 0.27543020248413086\n",
      "the process time is 0.2761716842651367\n",
      "the process time is 0.2945859432220459\n",
      "the process time is 0.2778451442718506\n",
      "the process time is 0.2754364013671875\n",
      "the process time is 0.27634668350219727\n",
      "the process time is 0.2785177230834961\n",
      "the process time is 0.27887535095214844\n",
      "the process time is 0.27379369735717773\n",
      "the process time is 0.271867036819458\n",
      "the process time is 0.27773547172546387\n",
      "the process time is 0.27447986602783203\n",
      "the process time is 0.27759766578674316\n",
      "the process time is 0.273212194442749\n",
      "the process time is 0.2730393409729004\n",
      "the process time is 0.27385497093200684\n",
      "the process time is 0.2714858055114746\n",
      "the process time is 0.2739386558532715\n",
      "the process time is 0.07178878784179688\n",
      "the process time is 0.2764778137207031\n",
      "the process time is 0.27543091773986816\n",
      "the process time is 0.2731955051422119\n",
      "the process time is 0.2753574848175049\n",
      "the process time is 0.27240920066833496\n",
      "the process time is 0.2714669704437256\n",
      "the process time is 0.07011866569519043\n",
      "the process time is 0.2833216190338135\n",
      "the process time is 0.2792937755584717\n",
      "the process time is 0.2799947261810303\n",
      "the process time is 0.07323360443115234\n",
      "the process time is 0.28377747535705566\n",
      "the process time is 0.273634672164917\n",
      "the process time is 0.27498483657836914\n",
      "the process time is 0.27344250679016113\n",
      "the process time is 0.27475690841674805\n",
      "the process time is 0.2766425609588623\n",
      "the process time is 0.274883508682251\n",
      "the process time is 0.2734241485595703\n",
      "the process time is 0.27524757385253906\n",
      "the process time is 0.2763094902038574\n",
      "the process time is 0.07395148277282715\n",
      "the process time is 0.07829403877258301\n",
      "the process time is 0.28165674209594727\n",
      "the process time is 0.09125757217407227\n",
      "the process time is 0.081695556640625\n",
      "the process time is 0.07360410690307617\n",
      "the process time is 0.07447528839111328\n",
      "the process time is 0.07719993591308594\n",
      "the process time is 0.07622885704040527\n",
      "the process time is 0.07603788375854492\n",
      "the process time is 0.10339522361755371\n",
      "the process time is 0.07683420181274414\n",
      "the process time is 0.07809925079345703\n",
      "the process time is 0.08011198043823242\n",
      "the process time is 0.07567858695983887\n",
      "the process time is 0.0752711296081543\n",
      "the process time is 0.08187508583068848\n",
      "the process time is 0.0758051872253418\n",
      "the process time is 0.07997894287109375\n",
      "the process time is 0.08150506019592285\n",
      "the process time is 0.07910633087158203\n",
      "the process time is 0.07883000373840332\n",
      "the process time is 0.07676410675048828\n",
      "the process time is 0.0792398452758789\n",
      "the process time is 0.07728266716003418\n",
      "the process time is 0.12157344818115234\n",
      "the process time is 0.07988357543945312\n",
      "the process time is 0.07273101806640625\n",
      "the process time is 0.07850289344787598\n",
      "the process time is 0.07945585250854492\n",
      "the process time is 0.08555936813354492\n",
      "the process time is 0.0779576301574707\n",
      "the process time is 0.10807538032531738\n",
      "the process time is 0.07933640480041504\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_path = \"./efficientnet1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"efficientnet_b3a\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the gesture recognition function\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "# Define the frame processing function\n",
    "def process_frames():\n",
    "    while True:\n",
    "        frame = frame_queue.get()\n",
    "        h, w, c = frame.shape\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            # Capture timestamp before cropping\n",
    "            start_time = time.time()\n",
    "            \n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "\n",
    "\n",
    "\n",
    "            # Capture timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate and print processing time\n",
    "            processing_time = end_time - start_time\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "# Define the helper functions (find_bounding_box, transform_frame, classify_gesture, display_gesture_prediction)\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Create a queue for passing frames between capture and processing threads\n",
    "frame_queue = queue.Queue(maxsize=5)\n",
    "\n",
    "# Create video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Start capture thread\n",
    "def capture_frames():\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        if not _:\n",
    "            break\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "\n",
    "# Start processing thread\n",
    "processing_thread = threading.Thread(target=process_frames)\n",
    "processing_thread.start()\n",
    "\n",
    "# Start capture thread\n",
    "capture_thread = threading.Thread(target=capture_frames)\n",
    "capture_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "capture_thread.join()\n",
    "processing_thread.join()\n",
    "\n",
    "# Release video capture object and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019c05e-de2f-41f3-b7de-fb16d352972f",
   "metadata": {},
   "source": [
    "## resnet50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31dec44-c802-4739-bd02-f4ffcd6de82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.3011937141418457\n",
      "the process time is 0.08226799964904785\n",
      "the process time is 0.09833812713623047\n",
      "the process time is 0.08973240852355957\n",
      "the process time is 0.2807731628417969\n",
      "the process time is 0.07016468048095703\n",
      "the process time is 0.27797722816467285\n",
      "the process time is 0.2789311408996582\n",
      "the process time is 0.07518982887268066\n",
      "the process time is 0.28362298011779785\n",
      "the process time is 0.2781379222869873\n",
      "the process time is 0.2785525321960449\n",
      "the process time is 0.27597570419311523\n",
      "the process time is 0.2738485336303711\n",
      "the process time is 0.2911202907562256\n",
      "the process time is 0.27601099014282227\n",
      "the process time is 0.27806973457336426\n",
      "the process time is 0.27904224395751953\n",
      "the process time is 0.26993227005004883\n",
      "the process time is 0.27349042892456055\n",
      "the process time is 0.2761387825012207\n",
      "the process time is 0.27544569969177246\n",
      "the process time is 0.27736496925354004\n",
      "the process time is 0.28522729873657227\n",
      "the process time is 0.273745059967041\n",
      "the process time is 0.27600574493408203\n",
      "the process time is 0.2682645320892334\n",
      "the process time is 0.27507925033569336\n",
      "the process time is 0.27559542655944824\n",
      "the process time is 0.28112339973449707\n",
      "the process time is 0.288008451461792\n",
      "the process time is 0.2776782512664795\n",
      "the process time is 0.2763335704803467\n",
      "the process time is 0.2862069606781006\n",
      "the process time is 0.28515124320983887\n",
      "the process time is 0.10651755332946777\n",
      "the process time is 0.1005091667175293\n",
      "the process time is 0.3054769039154053\n",
      "the process time is 0.3025798797607422\n",
      "the process time is 0.3046753406524658\n",
      "the process time is 0.3095695972442627\n",
      "the process time is 0.3027629852294922\n",
      "the process time is 0.3042788505554199\n",
      "the process time is 0.3008432388305664\n",
      "the process time is 0.30368995666503906\n",
      "the process time is 0.3038163185119629\n",
      "the process time is 0.3023703098297119\n",
      "the process time is 0.31401681900024414\n",
      "the process time is 0.30031490325927734\n",
      "the process time is 0.2943384647369385\n",
      "the process time is 0.304044246673584\n",
      "the process time is 0.31791043281555176\n",
      "the process time is 0.29929280281066895\n",
      "the process time is 0.3117706775665283\n",
      "the process time is 0.0959928035736084\n",
      "the process time is 0.09480571746826172\n",
      "the process time is 0.1070566177368164\n",
      "the process time is 0.3097679615020752\n",
      "the process time is 0.10595273971557617\n",
      "the process time is 0.10394501686096191\n",
      "the process time is 0.10432553291320801\n",
      "the process time is 0.6172940731048584\n",
      "the process time is 0.3042004108428955\n",
      "the process time is 0.30333805084228516\n",
      "the process time is 0.10581731796264648\n",
      "the process time is 0.10716748237609863\n",
      "the process time is 0.30849194526672363\n",
      "the process time is 0.10229301452636719\n",
      "the process time is 0.11084938049316406\n",
      "the process time is 0.09892892837524414\n",
      "the process time is 0.09830427169799805\n",
      "the process time is 0.10297703742980957\n",
      "the process time is 0.11488223075866699\n",
      "the process time is 0.3054332733154297\n",
      "the process time is 0.31431126594543457\n",
      "the process time is 0.10331606864929199\n",
      "the process time is 0.21296954154968262\n",
      "the process time is 0.10586166381835938\n",
      "the process time is 0.10683131217956543\n",
      "the process time is 0.09871840476989746\n",
      "the process time is 0.0935509204864502\n",
      "the process time is 0.09878683090209961\n",
      "the process time is 0.10584449768066406\n",
      "the process time is 0.10270571708679199\n",
      "the process time is 0.10337233543395996\n",
      "the process time is 0.3067436218261719\n",
      "the process time is 0.3306422233581543\n",
      "the process time is 0.3087913990020752\n",
      "the process time is 0.29628968238830566\n",
      "the process time is 0.3017117977142334\n",
      "the process time is 0.30719971656799316\n",
      "the process time is 0.10486245155334473\n",
      "the process time is 0.10331058502197266\n",
      "the process time is 0.3078780174255371\n",
      "the process time is 0.314955472946167\n",
      "the process time is 0.30242371559143066\n",
      "the process time is 0.3070816993713379\n",
      "the process time is 0.10985255241394043\n",
      "the process time is 0.1033773422241211\n",
      "the process time is 0.10485506057739258\n",
      "the process time is 0.10886049270629883\n",
      "the process time is 0.10902142524719238\n",
      "the process time is 0.10783505439758301\n",
      "the process time is 0.10184931755065918\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_path = \"./resnet50d_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"resnet50d\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the gesture recognition function\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "# Define the frame processing function\n",
    "def process_frames():\n",
    "    while True:\n",
    "        frame = frame_queue.get()\n",
    "        h, w, c = frame.shape\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            # Capture timestamp before cropping\n",
    "            start_time = time.time()\n",
    "            \n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "\n",
    "\n",
    "\n",
    "            # Capture timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate and print processing time\n",
    "            processing_time = end_time - start_time\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "# Define the helper functions (find_bounding_box, transform_frame, classify_gesture, display_gesture_prediction)\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Create a queue for passing frames between capture and processing threads\n",
    "frame_queue = queue.Queue(maxsize=5)\n",
    "\n",
    "# Create video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Start capture thread\n",
    "def capture_frames():\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        if not _:\n",
    "            break\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "\n",
    "# Start processing thread\n",
    "processing_thread = threading.Thread(target=process_frames)\n",
    "processing_thread.start()\n",
    "\n",
    "# Start capture thread\n",
    "capture_thread = threading.Thread(target=capture_frames)\n",
    "capture_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "capture_thread.join()\n",
    "processing_thread.join()\n",
    "\n",
    "# Release video capture object and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408b020b-6ec5-4d0e-9972-d1317ec77889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pytorchMethod\\pytorchClassification2\\pytorchEnv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.05387282371520996\n",
      "the process time is 0.023761272430419922\n",
      "the process time is 0.03233194351196289\n",
      "the process time is 0.031242847442626953\n",
      "the process time is 0.031410932540893555\n",
      "the process time is 0.031603336334228516\n",
      "the process time is 0.030266284942626953\n",
      "the process time is 0.031021595001220703\n",
      "the process time is 0.030955076217651367\n",
      "the process time is 0.031164884567260742\n",
      "the process time is 0.031006336212158203\n",
      "the process time is 0.03130388259887695\n",
      "the process time is 0.03177928924560547\n",
      "the process time is 0.030415058135986328\n",
      "the process time is 0.03088212013244629\n",
      "the process time is 0.030794858932495117\n",
      "the process time is 0.030965805053710938\n",
      "the process time is 0.03136897087097168\n",
      "the process time is 0.3585853576660156\n",
      "the process time is 0.3581109046936035\n",
      "the process time is 0.6240332126617432\n",
      "the process time is 0.2956080436706543\n",
      "the process time is 0.6396834850311279\n",
      "the process time is 0.10399389266967773\n",
      "the process time is 0.35625147819519043\n",
      "the process time is 0.3287825584411621\n",
      "the process time is 0.332425594329834\n",
      "the process time is 0.3281259536743164\n",
      "the process time is 0.12753629684448242\n",
      "the process time is 0.34357547760009766\n",
      "the process time is 0.6226334571838379\n",
      "the process time is 0.310528039932251\n",
      "the process time is 0.1472771167755127\n",
      "the process time is 0.12054920196533203\n",
      "the process time is 0.13998961448669434\n",
      "the process time is 0.333209753036499\n",
      "the process time is 0.1251049041748047\n",
      "the process time is 0.14118385314941406\n",
      "the process time is 0.15502119064331055\n",
      "the process time is 0.3285179138183594\n",
      "the process time is 0.33045434951782227\n",
      "the process time is 0.32642412185668945\n",
      "the process time is 0.3263216018676758\n",
      "the process time is 0.12224793434143066\n",
      "the process time is 0.057694435119628906\n",
      "the process time is 0.047142744064331055\n",
      "the process time is 0.027152538299560547\n",
      "the process time is 0.037386417388916016\n",
      "the process time is 0.0381319522857666\n",
      "the process time is 0.03142404556274414\n",
      "the process time is 0.031630516052246094\n",
      "the process time is 0.0266265869140625\n",
      "the process time is 0.02624058723449707\n",
      "the process time is 0.03799319267272949\n",
      "the process time is 0.02684187889099121\n",
      "the process time is 0.026137113571166992\n",
      "the process time is 0.038316965103149414\n",
      "the process time is 0.03278803825378418\n",
      "the process time is 0.025167226791381836\n",
      "the process time is 0.038765907287597656\n",
      "the process time is 0.037841796875\n",
      "the process time is 0.02429819107055664\n",
      "the process time is 0.023271799087524414\n",
      "the process time is 0.03527069091796875\n",
      "the process time is 0.027805328369140625\n",
      "the process time is 0.028217315673828125\n",
      "the process time is 0.03084850311279297\n",
      "the process time is 0.026660442352294922\n",
      "the process time is 0.025727033615112305\n",
      "the process time is 0.02936530113220215\n",
      "the process time is 0.02926468849182129\n",
      "the process time is 0.02506875991821289\n",
      "the process time is 0.034655094146728516\n",
      "the process time is 0.033661603927612305\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "model_path = \"./resnet50d_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"resnet50d\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "    \n",
    "        #do nothing\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Downsample factor (skip every N frames)\n",
    "downsample_factor = 2\n",
    "downsample_counter = 0\n",
    "classA=\"nothing\"\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "    # Downsample frames\n",
    "    if downsample_counter % downsample_factor == 0:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                classA= classes_names[predicted_class]\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        \n",
    "        # Get timestamp after processing and before showing the frame\n",
    "        end_time = time.time()\n",
    "        # Calculate processing time\n",
    "        processing_time = end_time - start_time\n",
    "        print(\"the process time is \"+ str(processing_time))\n",
    "            \n",
    "    else:\n",
    "            gesture_control(classA)\n",
    "\n",
    "    downsample_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5c621d-0fc3-4bc6-8768-9a56d137d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.28357815742492676\n",
      "the process time is 0.2803187370300293\n",
      "the process time is 0.2847874164581299\n",
      "the process time is 0.5572443008422852\n",
      "the process time is 0.28423047065734863\n",
      "the process time is 0.28098392486572266\n",
      "the process time is 0.5631608963012695\n",
      "the process time is 0.28581738471984863\n",
      "the process time is 0.2795882225036621\n",
      "the process time is 0.2771422863006592\n",
      "the process time is 0.280531644821167\n",
      "the process time is 0.5623283386230469\n",
      "the process time is 0.28491997718811035\n",
      "the process time is 0.5575873851776123\n",
      "the process time is 0.2759435176849365\n",
      "the process time is 0.5524685382843018\n",
      "the process time is 0.27828431129455566\n",
      "the process time is 0.28847718238830566\n",
      "the process time is 0.5675716400146484\n",
      "the process time is 0.2787160873413086\n",
      "the process time is 0.5557639598846436\n",
      "the process time is 0.07411789894104004\n",
      "the process time is 0.15107011795043945\n",
      "the process time is 0.08267045021057129\n",
      "the process time is 0.28304481506347656\n",
      "the process time is 0.2757601737976074\n",
      "the process time is 0.280811071395874\n",
      "the process time is 0.28268003463745117\n",
      "the process time is 0.28919458389282227\n",
      "the process time is 0.28617167472839355\n",
      "the process time is 0.27846550941467285\n",
      "the process time is 0.2774968147277832\n",
      "the process time is 0.2949831485748291\n",
      "the process time is 0.07984113693237305\n",
      "the process time is 0.28418827056884766\n",
      "the process time is 0.2824115753173828\n",
      "the process time is 0.2807166576385498\n",
      "the process time is 0.07614684104919434\n",
      "the process time is 0.08566594123840332\n",
      "the process time is 0.2816505432128906\n",
      "the process time is 0.08649373054504395\n",
      "the process time is 0.07705044746398926\n",
      "the process time is 0.07858133316040039\n",
      "the process time is 0.28173041343688965\n",
      "the process time is 0.07684707641601562\n",
      "the process time is 0.28978586196899414\n",
      "the process time is 0.28858017921447754\n",
      "the process time is 0.278545618057251\n",
      "the process time is 0.27742552757263184\n",
      "the process time is 0.36174774169921875\n",
      "the process time is 0.07771420478820801\n",
      "the process time is 0.28427791595458984\n",
      "the process time is 0.08232498168945312\n",
      "the process time is 0.09712052345275879\n",
      "the process time is 0.0796051025390625\n",
      "the process time is 0.08307623863220215\n",
      "the process time is 0.08485937118530273\n",
      "the process time is 0.08035969734191895\n",
      "the process time is 0.08135628700256348\n",
      "the process time is 0.08332133293151855\n",
      "the process time is 0.284515380859375\n",
      "the process time is 0.2811880111694336\n",
      "the process time is 0.2808105945587158\n",
      "the process time is 0.2788107395172119\n",
      "the process time is 0.2792811393737793\n",
      "the process time is 0.2797434329986572\n",
      "the process time is 0.2773892879486084\n",
      "the process time is 0.08229327201843262\n",
      "the process time is 0.08482956886291504\n",
      "the process time is 0.3686347007751465\n",
      "the process time is 0.2789461612701416\n",
      "the process time is 0.27642369270324707\n",
      "the process time is 0.08862066268920898\n",
      "the process time is 0.369675874710083\n",
      "the process time is 0.28323888778686523\n",
      "the process time is 0.2747352123260498\n",
      "the process time is 0.278118371963501\n",
      "the process time is 0.28175950050354004\n",
      "the process time is 0.28162431716918945\n",
      "the process time is 0.2886505126953125\n",
      "the process time is 0.08093643188476562\n",
      "the process time is 0.2817728519439697\n",
      "the process time is 0.08668947219848633\n",
      "the process time is 0.08683633804321289\n",
      "the process time is 0.07927513122558594\n",
      "the process time is 0.08848118782043457\n",
      "the process time is 0.07715749740600586\n",
      "the process time is 0.08238077163696289\n",
      "the process time is 0.07768797874450684\n",
      "the process time is 0.07821059226989746\n",
      "the process time is 0.08888101577758789\n",
      "the process time is 0.07907748222351074\n",
      "the process time is 0.08500504493713379\n",
      "the process time is 0.283156156539917\n",
      "the process time is 0.2759573459625244\n",
      "the process time is 0.08882379531860352\n",
      "the process time is 0.28945446014404297\n",
      "the process time is 0.2772533893585205\n",
      "the process time is 0.28162646293640137\n",
      "the process time is 0.6235888004302979\n",
      "the process time is 0.28330278396606445\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "# MediaPipe Hands initialization\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "# GPU availability check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Gesture recognition model path and class names\n",
    "model_path = \"./resnet50d_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"resnet50d\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to get PyTorch transforms\n",
    "def get_torch_transforms(img_size=224):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomRotation((-5, 5)),\n",
    "            transforms.RandomAutocontrast(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "\n",
    "    if hand_landmarks:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for index, handLMs in enumerate(hand_landmarks):\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "\n",
    "            x_min = max(0, x_min - 50)\n",
    "            y_min = max(0, y_min - 50)\n",
    "            x_max = min(w, x_max + 50)\n",
    "            y_max = min(h, y_max + 50)\n",
    "\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "           \n",
    "            \n",
    "            cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "            input_tensor = transform(cropped_frame).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                probabilities = F.softmax(output[0], dim=0)\n",
    "                predicted_class = torch.argmax(probabilities).item()\n",
    "                #use getsure control it\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                #end of it\n",
    "                predict_name = classes_names[predicted_class] + \" for Hand \" + str(index + 1)\n",
    "\n",
    "\n",
    "            cv2.putText(frame, predict_name, (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "            # Get timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate processing time\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        #\"esc\" to quit\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2d8c0-d6c0-40e3-bf08-ba09693390df",
   "metadata": {},
   "source": [
    "##  vit_tiny_patch16_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d2e2e0-6be5-47a4-8fb2-e55f8f37f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.031655073165893555\n",
      "the process time is 0.027419567108154297\n",
      "the process time is 0.2321782112121582\n",
      "the process time is 0.03368043899536133\n",
      "the process time is 0.03470015525817871\n",
      "the process time is 0.06879162788391113\n",
      "the process time is 0.031538963317871094\n",
      "the process time is 0.0357213020324707\n",
      "the process time is 0.028597116470336914\n",
      "the process time is 0.0305330753326416\n",
      "the process time is 0.028260231018066406\n",
      "the process time is 0.029580354690551758\n",
      "the process time is 0.26087498664855957\n",
      "the process time is 0.027692317962646484\n",
      "the process time is 0.03080272674560547\n",
      "the process time is 0.026726245880126953\n",
      "the process time is 0.030825376510620117\n",
      "the process time is 0.026008129119873047\n",
      "the process time is 0.2295849323272705\n",
      "the process time is 0.22879242897033691\n",
      "the process time is 0.024541616439819336\n",
      "the process time is 0.031116247177124023\n",
      "the process time is 0.029590845108032227\n",
      "the process time is 0.026777267456054688\n",
      "the process time is 0.029705286026000977\n",
      "the process time is 0.04316544532775879\n",
      "the process time is 0.030124902725219727\n",
      "the process time is 0.028791189193725586\n",
      "the process time is 0.027426481246948242\n",
      "the process time is 0.230543851852417\n",
      "the process time is 0.22843551635742188\n",
      "the process time is 0.22955727577209473\n",
      "the process time is 0.2280116081237793\n",
      "the process time is 0.2292156219482422\n",
      "the process time is 0.23162579536437988\n",
      "the process time is 0.2273397445678711\n",
      "the process time is 0.22633576393127441\n",
      "the process time is 0.22724461555480957\n",
      "the process time is 0.22329926490783691\n",
      "the process time is 0.2321624755859375\n",
      "the process time is 0.22962069511413574\n",
      "the process time is 0.2303171157836914\n",
      "the process time is 0.22888708114624023\n",
      "the process time is 0.22385907173156738\n",
      "the process time is 0.23041629791259766\n",
      "the process time is 0.22645020484924316\n",
      "the process time is 0.02818584442138672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "# MediaPipe Hands initialization\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "# GPU availability check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Gesture recognition model path and class names\n",
    "model_path = \"./vit_tiny_patch16_224_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"vit_tiny_patch16_224\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to get PyTorch transforms\n",
    "def get_torch_transforms(img_size=224):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomRotation((-5, 5)),\n",
    "            transforms.RandomAutocontrast(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the gesture recognition model\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "\n",
    "    if hand_landmarks:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for index, handLMs in enumerate(hand_landmarks):\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "\n",
    "            x_min = max(0, x_min - 50)\n",
    "            y_min = max(0, y_min - 50)\n",
    "            x_max = min(w, x_max + 50)\n",
    "            y_max = min(h, y_max + 50)\n",
    "\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "           \n",
    "            \n",
    "            cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "            input_tensor = transform(cropped_frame).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                probabilities = F.softmax(output[0], dim=0)\n",
    "                predicted_class = torch.argmax(probabilities).item()\n",
    "                #use getsure control it\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                #end of it\n",
    "                predict_name = classes_names[predicted_class] + \" for Hand \" + str(index + 1)\n",
    "\n",
    "\n",
    "            cv2.putText(frame, predict_name, (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "            # Get timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate processing time\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        #\"esc\" to quit\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143111f4-7086-4f38-ae0f-f2a205ea7426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.06196236610412598\n",
      "the process time is 0.030739307403564453\n",
      "the process time is 0.030701160430908203\n",
      "the process time is 0.04758858680725098\n",
      "the process time is 0.03732442855834961\n",
      "the process time is 0.030889272689819336\n",
      "the process time is 0.030218839645385742\n",
      "the process time is 0.031404733657836914\n",
      "the process time is 0.03101038932800293\n",
      "the process time is 0.03103923797607422\n",
      "the process time is 0.030649662017822266\n",
      "the process time is 0.03205537796020508\n",
      "the process time is 0.03085923194885254\n",
      "the process time is 0.03078007698059082\n",
      "the process time is 0.03075265884399414\n",
      "the process time is 0.030982017517089844\n",
      "the process time is 0.03167724609375\n",
      "the process time is 0.03149819374084473\n",
      "the process time is 0.030037879943847656\n",
      "the process time is 0.030988454818725586\n",
      "the process time is 0.031574249267578125\n",
      "the process time is 0.03141522407531738\n",
      "the process time is 0.031339406967163086\n",
      "the process time is 0.09270715713500977\n",
      "the process time is 0.12429261207580566\n",
      "the process time is 0.0621190071105957\n",
      "the process time is 0.07799744606018066\n",
      "the process time is 0.07811999320983887\n",
      "the process time is 0.12502789497375488\n",
      "the process time is 0.07836675643920898\n",
      "the process time is 0.12606501579284668\n",
      "the process time is 0.06269359588623047\n",
      "the process time is 0.12411046028137207\n",
      "the process time is 0.06300544738769531\n",
      "the process time is 0.09348392486572266\n",
      "the process time is 0.09397149085998535\n",
      "the process time is 0.09326624870300293\n",
      "the process time is 0.07827067375183105\n",
      "the process time is 0.07777094841003418\n",
      "the process time is 0.07940435409545898\n",
      "the process time is 0.07802319526672363\n",
      "the process time is 0.07881999015808105\n",
      "the process time is 0.07308697700500488\n",
      "the process time is 0.10242247581481934\n",
      "the process time is 0.08082175254821777\n",
      "the process time is 0.0838766098022461\n",
      "the process time is 0.0980675220489502\n",
      "the process time is 0.07891845703125\n",
      "the process time is 0.07714581489562988\n",
      "the process time is 0.09499049186706543\n",
      "the process time is 0.28333425521850586\n",
      "the process time is 0.2817113399505615\n",
      "the process time is 0.07845115661621094\n",
      "the process time is 0.1225883960723877\n",
      "the process time is 0.16823458671569824\n",
      "the process time is 0.11007094383239746\n",
      "the process time is 0.0862421989440918\n",
      "the process time is 0.09499502182006836\n",
      "the process time is 0.0795736312866211\n",
      "the process time is 0.09043455123901367\n",
      "the process time is 0.27859067916870117\n",
      "the process time is 0.26546216011047363\n",
      "the process time is 0.26615214347839355\n",
      "the process time is 0.29598546028137207\n",
      "the process time is 0.28098607063293457\n",
      "the process time is 0.10857009887695312\n",
      "the process time is 0.2790646553039551\n",
      "the process time is 0.2844252586364746\n",
      "the process time is 0.27025508880615234\n",
      "the process time is 0.276763916015625\n",
      "the process time is 0.2785177230834961\n",
      "the process time is 0.05742764472961426\n",
      "the process time is 0.030903100967407227\n",
      "the process time is 0.0338292121887207\n",
      "the process time is 0.02768421173095703\n",
      "the process time is 0.031136035919189453\n",
      "the process time is 0.02557229995727539\n",
      "the process time is 0.03707575798034668\n",
      "the process time is 0.021378755569458008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "model_path = \"./vit_tiny_patch16_224_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"vit_tiny_patch16_224\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "    \n",
    "        #do nothing\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Downsample factor (skip every N frames)\n",
    "downsample_factor = 2\n",
    "downsample_counter = 0\n",
    "classA=\"nothing\"\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    h, w, c = frame.shape\n",
    "    if not _:\n",
    "        break\n",
    "    # Downsample frames\n",
    "    if downsample_counter % downsample_factor == 0:\n",
    "        # Get timestamp before cropping\n",
    "        start_time = time.time()\n",
    "        \n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                classA= classes_names[predicted_class]\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        \n",
    "        # Get timestamp after processing and before showing the frame\n",
    "        end_time = time.time()\n",
    "        # Calculate processing time\n",
    "        processing_time = end_time - start_time\n",
    "        print(\"the process time is \"+ str(processing_time))\n",
    "            \n",
    "    else:\n",
    "            gesture_control(classA)\n",
    "\n",
    "    downsample_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c368c-d35c-4745-a2a9-e91ba849fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process time is 0.2686443328857422\n",
      "the process time is 0.2940218448638916\n",
      "the process time is 0.26572227478027344\n",
      "the process time is 0.27216172218322754\n",
      "the process time is 0.03658914566040039\n",
      "the process time is 0.029598474502563477\n",
      "the process time is 0.039162397384643555\n",
      "the process time is 0.2352914810180664\n",
      "the process time is 0.23135161399841309\n",
      "the process time is 0.24903631210327148\n",
      "the process time is 0.22946763038635254\n",
      "the process time is 0.23226690292358398\n",
      "the process time is 0.2397758960723877\n",
      "the process time is 0.2298414707183838\n",
      "the process time is 0.22711873054504395\n",
      "the process time is 0.22739839553833008\n",
      "the process time is 0.22806549072265625\n",
      "the process time is 0.23130011558532715\n",
      "the process time is 0.22897863388061523\n",
      "the process time is 0.22956037521362305\n",
      "the process time is 0.23091888427734375\n",
      "the process time is 0.2302541732788086\n",
      "the process time is 0.22874879837036133\n",
      "the process time is 0.4581434726715088\n",
      "the process time is 0.45542025566101074\n",
      "the process time is 0.46124267578125\n",
      "the process time is 0.45596909523010254\n",
      "the process time is 0.45989274978637695\n",
      "the process time is 0.26106786727905273\n",
      "the process time is 0.457869291305542\n",
      "the process time is 0.22587323188781738\n",
      "the process time is 0.2603950500488281\n",
      "the process time is 0.027593612670898438\n",
      "the process time is 0.030461549758911133\n",
      "the process time is 0.027560710906982422\n",
      "the process time is 0.030063152313232422\n",
      "the process time is 0.03145313262939453\n",
      "the process time is 0.03129434585571289\n",
      "the process time is 0.028568267822265625\n",
      "the process time is 0.030552387237548828\n",
      "the process time is 0.026555776596069336\n",
      "the process time is 0.03157639503479004\n",
      "the process time is 0.025545358657836914\n",
      "the process time is 0.2318897247314453\n",
      "the process time is 0.027050256729125977\n",
      "the process time is 0.2352004051208496\n",
      "the process time is 0.23086237907409668\n",
      "the process time is 0.22735834121704102\n",
      "the process time is 0.22982287406921387\n",
      "the process time is 0.22902512550354004\n",
      "the process time is 0.02557969093322754\n",
      "the process time is 0.027556180953979492\n",
      "the process time is 0.0301058292388916\n",
      "the process time is 0.0310823917388916\n",
      "the process time is 0.23145508766174316\n",
      "the process time is 0.23029613494873047\n",
      "the process time is 0.22763609886169434\n",
      "the process time is 0.22886991500854492\n",
      "the process time is 0.22967839241027832\n",
      "the process time is 0.22762751579284668\n",
      "the process time is 0.2249763011932373\n",
      "the process time is 0.22772955894470215\n",
      "the process time is 0.2326822280883789\n",
      "the process time is 0.22958111763000488\n",
      "the process time is 0.22934842109680176\n",
      "the process time is 0.23099875450134277\n",
      "the process time is 0.0265805721282959\n",
      "the process time is 0.24266982078552246\n",
      "the process time is 0.22611212730407715\n",
      "the process time is 0.22627806663513184\n",
      "the process time is 0.229142427444458\n",
      "the process time is 0.23106956481933594\n",
      "the process time is 0.22849822044372559\n",
      "the process time is 0.22625279426574707\n",
      "the process time is 0.22888970375061035\n",
      "the process time is 0.2337656021118164\n",
      "the process time is 0.22643136978149414\n",
      "the process time is 0.22792315483093262\n",
      "the process time is 0.23055815696716309\n",
      "the process time is 0.22686123847961426\n",
      "the process time is 0.23238587379455566\n",
      "the process time is 0.04013991355895996\n",
      "the process time is 0.05517148971557617\n",
      "the process time is 0.028046369552612305\n",
      "the process time is 0.026037216186523438\n",
      "the process time is 0.027560710906982422\n",
      "the process time is 0.02907562255859375\n",
      "the process time is 0.02405571937561035\n",
      "the process time is 0.023550987243652344\n",
      "the process time is 0.03409004211425781\n",
      "the process time is 0.02504706382751465\n",
      "the process time is 0.02802252769470215\n",
      "the process time is 0.02503800392150879\n",
      "the process time is 0.026567935943603516\n",
      "the process time is 0.026065587997436523\n",
      "the process time is 0.025576114654541016\n",
      "the process time is 0.02253556251525879\n",
      "the process time is 0.026570558547973633\n",
      "the process time is 0.023030757904052734\n",
      "the process time is 0.2241058349609375\n",
      "the process time is 0.0406346321105957\n",
      "the process time is 0.039423227310180664\n",
      "the process time is 0.24469256401062012\n",
      "the process time is 0.22722792625427246\n",
      "the process time is 0.2402660846710205\n",
      "the process time is 0.2533750534057617\n",
      "the process time is 0.24514484405517578\n",
      "the process time is 0.02410578727722168\n",
      "the process time is 0.03399658203125\n",
      "the process time is 0.028178691864013672\n",
      "the process time is 0.022037506103515625\n",
      "the process time is 0.025063037872314453\n",
      "the process time is 0.037587881088256836\n",
      "the process time is 0.027550458908081055\n",
      "the process time is 0.0250394344329834\n",
      "the process time is 0.02454400062561035\n",
      "the process time is 0.029367923736572266\n",
      "the process time is 0.028071165084838867\n",
      "the process time is 0.027034521102905273\n",
      "the process time is 0.028560400009155273\n",
      "the process time is 0.029587268829345703\n",
      "the process time is 0.023405790328979492\n",
      "the process time is 0.031572580337524414\n",
      "the process time is 0.027561187744140625\n",
      "the process time is 0.02703070640563965\n",
      "the process time is 0.028151750564575195\n",
      "the process time is 0.027753829956054688\n",
      "the process time is 0.05156564712524414\n",
      "the process time is 0.0213165283203125\n",
      "the process time is 0.05622148513793945\n",
      "the process time is 0.02618122100830078\n",
      "the process time is 0.026551485061645508\n",
      "the process time is 0.07159900665283203\n",
      "the process time is 0.22693395614624023\n",
      "the process time is 0.024057388305664062\n",
      "the process time is 0.025033235549926758\n",
      "the process time is 0.026494741439819336\n",
      "the process time is 0.027489185333251953\n",
      "the process time is 0.026551485061645508\n",
      "the process time is 0.026552200317382812\n",
      "the process time is 0.02353501319885254\n",
      "the process time is 0.22630763053894043\n",
      "the process time is 0.22250890731811523\n",
      "the process time is 0.22772693634033203\n",
      "the process time is 0.02403998374938965\n",
      "the process time is 0.22681069374084473\n",
      "the process time is 0.2264564037322998\n",
      "the process time is 0.22281217575073242\n",
      "the process time is 0.02554178237915039\n",
      "the process time is 0.026559114456176758\n",
      "the process time is 0.22708463668823242\n",
      "the process time is 0.022043228149414062\n",
      "the process time is 0.027541637420654297\n",
      "the process time is 0.022535324096679688\n",
      "the process time is 0.02505779266357422\n",
      "the process time is 0.0295565128326416\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_path = \"./vit_tiny_patch16_224_1.pth\"\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "                 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"vit_tiny_patch16_224\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, out_features)\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the gesture recognition function\n",
    "def gesture_control(recognized_gestures):\n",
    "    if 'space' in recognized_gestures:\n",
    "        pyautogui.keyDown('e')\n",
    "        pyautogui.keyUp('e')\n",
    "    elif 'O' in recognized_gestures:\n",
    "        pyautogui.keyDown('q')\n",
    "        pyautogui.keyUp('q')\n",
    "    elif 'N' in recognized_gestures:\n",
    "        pyautogui.keyDown('w')\n",
    "        pyautogui.keyUp('w')\n",
    "    elif 'B' in recognized_gestures:\n",
    "        pyautogui.keyDown('s')\n",
    "        pyautogui.keyUp('s')\n",
    "    elif 'S' in recognized_gestures:\n",
    "        pyautogui.keyDown('a')\n",
    "        pyautogui.keyUp('a')\n",
    "    elif 'F' in recognized_gestures:\n",
    "        pyautogui.keyDown('d')\n",
    "        pyautogui.keyUp('d')\n",
    "\n",
    "\n",
    "# Define the frame processing function\n",
    "def process_frames():\n",
    "    while True:\n",
    "        frame = frame_queue.get()\n",
    "        h, w, c = frame.shape\n",
    "        framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(framergb)\n",
    "        hand_landmarks = result.multi_hand_landmarks\n",
    "        if hand_landmarks:\n",
    "            # Capture timestamp before cropping\n",
    "            start_time = time.time()\n",
    "            \n",
    "            index = 0\n",
    "            while index < len(hand_landmarks):\n",
    "                handLMs = hand_landmarks[index]\n",
    "                x_min, y_min, x_max, y_max = find_bounding_box(handLMs.landmark, w, h)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "                input_tensor = transform_frame(cropped_frame)\n",
    "                predicted_class = classify_gesture(model, input_tensor, classes_names)\n",
    "                gesture_control(classes_names[predicted_class])\n",
    "                display_gesture_prediction(frame, classes_names[predicted_class], index)\n",
    "                index += 1\n",
    "\n",
    "\n",
    "\n",
    "            # Capture timestamp after processing and before showing the frame\n",
    "            end_time = time.time()\n",
    "            # Calculate and print processing time\n",
    "            processing_time = end_time - start_time\n",
    "            print(\"the process time is \"+ str(processing_time))\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(frame, \"nothing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "# Define the helper functions (find_bounding_box, transform_frame, classify_gesture, display_gesture_prediction)\n",
    "\n",
    "\n",
    "def find_bounding_box(landmarks, w, h):\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    # Add a margin of 50 pixels to the bounding box\n",
    "    x_min, y_min = max(0, x_min - 50), max(0, y_min - 50)\n",
    "    x_max, y_max = min(w, x_max + 50), min(h, y_max + 50)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "def transform_frame(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "\n",
    "def classify_gesture(model, input_tensor, classes_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "def display_gesture_prediction(frame, gesture_name, index):\n",
    "    cv2.putText(frame, f\"{gesture_name} for Hand {index + 1}\", (10, 30 + 30 * index), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0 + index * 100, 0), 2)\n",
    "\n",
    "\n",
    "model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "weights = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found or cannot be opened.\")\n",
    "index = 0\n",
    "\n",
    "# Create a queue for passing frames between capture and processing threads\n",
    "frame_queue = queue.Queue(maxsize=5)\n",
    "\n",
    "# Create video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Start capture thread\n",
    "def capture_frames():\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        if not _:\n",
    "            break\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "\n",
    "# Start processing thread\n",
    "processing_thread = threading.Thread(target=process_frames)\n",
    "processing_thread.start()\n",
    "\n",
    "# Start capture thread\n",
    "capture_thread = threading.Thread(target=capture_frames)\n",
    "capture_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "capture_thread.join()\n",
    "processing_thread.join()\n",
    "\n",
    "# Release video capture object and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
