{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca687ba-a461-4a44-a611-20401b4b3212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: A_test.jpg result A\n",
      "2: B_test.jpg result B\n",
      "3: C_test.jpg result C\n",
      "4: D_test.jpg result D\n",
      "5: E_test.jpg result E\n",
      "6: F_test.jpg result F\n",
      "7: G_test.jpg result G\n",
      "8: H_test.jpg result H\n",
      "9: I_test.jpg result I\n",
      "10: J_test.jpg result J\n",
      "11: K_test.jpg result K\n",
      "12: L_test.jpg result L\n",
      "13: M_test.jpg result M\n",
      "14: nothing_test.jpg result nothing\n",
      "15: N_test.jpg result N\n",
      "16: O_test.jpg result O\n",
      "17: P_test.jpg result P\n",
      "18: Q_test.jpg result Q\n",
      "19: R_test.jpg result R\n",
      "20: space_test.jpg result space\n",
      "21: S_test.jpg result S\n",
      "22: T_test.jpg result T\n",
      "23: U_test.jpg result U\n",
      "24: V_test.jpg result V\n",
      "25: W_test.jpg result W\n",
      "26: X_test.jpg result X\n",
      "27: Y_test.jpg result Y\n",
      "28: Z_test.jpg result Z\n",
      "1: aa.jpg result Y\n",
      "2: b.jpg result O\n",
      "3: bb.jpg result space\n",
      "4: bbbbbb.jpg result space\n",
      "5: cc.jpg result C\n",
      "6: cccc.jpg result F\n",
      "7: dd.jpg result Y\n",
      "8: dddd.jpg result F\n",
      "9: ee.jpg result J\n",
      "10: ff.jpg result O\n",
      "11: gg.jpg result P\n",
      "12: hh.jpg result H\n",
      "13: jj.jpg result space\n",
      "14: kk.jpg result Z\n",
      "15: ll.jpg result space\n",
      "16: llll.jpg result space\n",
      "17: mmm.jpg result J\n",
      "18: nothing.jpg result nothing\n",
      "19: ooo.jpg result Q\n",
      "20: pppp.jpg result P\n",
      "21: qqqq.jpg result C\n",
      "22: rrr.jpg result Z\n",
      "23: rrrrrr.jpg result space\n",
      "24: space.jpg result del\n",
      "25: ssss.jpg result space\n",
      "26: sssss.jpg result space\n",
      "27: tt.jpg result space\n",
      "28: uu.jpg result Z\n",
      "29: vv.jpg result R\n",
      "30: www.jpg result J\n",
      "31: xxx.jpg result space\n",
      "32: yyy.jpg result Y\n",
      "33: zzzz.jpg result space\n",
      "123.jpg's result is Y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "# from train_resnet import SelfNet\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "\n",
    "# set to gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_path = \"./savefile/vit_tiny_patch16_224_pretrained_224/vit_tiny_patch16_224_9epochs_accuracy0.99922_weights.pth\"\n",
    "# 'A', 'B', 'Blank', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "classes_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "img_size = 224\n",
    "model_name = \"vit_tiny_patch16_224\"\n",
    "num_classes = len(classes_names)\n",
    "\n",
    "# ---------\n",
    "\n",
    "# define the model\n",
    "class SELFMODEL(nn.Module):\n",
    "    def __init__(self, model_name, out_features=num_classes,\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)  # load pretrained model\n",
    "        # classifier\n",
    "        if model_name[:3] == \"res\":\n",
    "            n_features = self.model.fc.in_features  # fix the connect layer number\n",
    "            self.model.fc = nn.Linear(n_features, out_features)  # change the class numebr\n",
    "        elif model_name[:3] == \"vit\":\n",
    "            n_features = self.model.head.in_features  # change full connect layer number\n",
    "            self.model.head = nn.Linear(n_features, out_features)\n",
    "        else:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, out_features)\n",
    "        # resnet  change the all connect layer\n",
    "    #     print(self.model)  # return model\n",
    "\n",
    "    def forward(self, x):  # front spreed\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_torch_transforms(img_size=224):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            # transforms.RandomResizedCrop(img_size),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomRotation((-5, 5)),\n",
    "            transforms.RandomAutocontrast(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            # transforms.Resize((img_size, img_size)),\n",
    "            # transforms.Resize(256),\n",
    "            # transforms.CenterCrop(img_size),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    # Convert input image to RGB format\n",
    "    # data_transforms['val'].transforms.insert(0, transforms.Grayscale(3))\n",
    "    return data_transforms\n",
    "\n",
    "# ---------\n",
    "\n",
    "\n",
    "def predict_batch(model_path, target_dir, save_dir):\n",
    "    data_transforms = get_torch_transforms(img_size=img_size)\n",
    "    valid_transforms = data_transforms['val']\n",
    "    # load the net\n",
    "    model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "    # model = nn.DataParallel(model)\n",
    "    weights = torch.load(model_path)\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # read picture\n",
    "    image_names = os.listdir(target_dir)\n",
    "    for i, image_name in enumerate(image_names):\n",
    "        image_path = osp.join(target_dir, image_name)\n",
    "        img = Image.open(image_path)\n",
    "        img = valid_transforms(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        output = model(img)\n",
    "        label_id = torch.argmax(output).item()\n",
    "        predict_name = classes_names[label_id]\n",
    "        save_path = osp.join(save_dir, predict_name)\n",
    "        if not osp.isdir(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        shutil.copy(image_path, save_path)\n",
    "        print(f\"{i + 1}: {image_name} result {predict_name}\")\n",
    "\n",
    "\n",
    "def predict_single(model_path, image_path):\n",
    "    data_transforms = get_torch_transforms(img_size=img_size)\n",
    "    # train_transforms = data_transforms['train']\n",
    "    valid_transforms = data_transforms['val']\n",
    "    # load the net\n",
    "    model = SELFMODEL(model_name=model_name, out_features=num_classes, pretrained=False)\n",
    "    # model = nn.DataParallel(model)\n",
    "    weights = torch.load(model_path)\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # read picture\n",
    "    img = Image.open(image_path)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = valid_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    output = model(img)\n",
    "    label_id = torch.argmax(output).item()\n",
    "    predict_name = classes_names[label_id]\n",
    "    print(f\"{image_path}'s result is {predict_name}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # bacth predict\n",
    "\n",
    "    # target_dir=\"./gesture_finalpredict/asl_alphabet_test\"\n",
    "    # predict_batch(model_path=model_path,target_dir=\"./americanSignGesture/professorhand/gesture_finalpredict/test2\",save_dir=\"./americanSignGesture/professorhand/gesture_finalpredict/theresultfortest2\")\n",
    "\n",
    "    predict_batch(model_path=model_path,target_dir=\"./gesture_finalpredict/asl_alphabet_test\",save_dir=\"./gesture_finalpredict/theresultfortest2\")\n",
    "    predict_batch(model_path=model_path,target_dir=\"./gesture_finalpredict/test2\",save_dir=\"./gesture_finalpredict/theresultfortest2\")\n",
    "\n",
    "    # single predict\n",
    "    #predict_single(model_path=model_path, image_path=\"123.jpg\")\n",
    "\n",
    "    # predict_single(model_path=model_path, image_path=\"2.jpg\")\n",
    "\n",
    "# predict_single(model_path=model_path, image_path=\"3.jpg\")\n",
    "\n",
    "#  predict_single(model_path=model_path, image_path=\"4.jpg\")\n",
    "\n",
    "#  predict_single(model_path=model_path, image_path=\"5.jpg\")\n",
    "\n",
    "#   predict_single(model_path=model_path, image_path=\"6.jpg\")\n",
    "\n",
    "#  predict_single(model_path=model_path, image_path=\"7.jpg\")\n",
    "\n",
    "#  predict_single(model_path=model_path, image_path=\"./gesture_finalpredict/test2/b.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
